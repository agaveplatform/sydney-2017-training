{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting Stuff Up</h2>\n",
    "\n",
    "Here we import some packages that we'll need in various places. We'll also load all the variables we set in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/agave\n",
      "Requirement already up-to-date: setvar in /opt/conda/lib/python3.6/site-packages\n",
      "AGAVE_JSON_PARSER=jq\n",
      "AGAVE_PASSWD=**HIDDEN**\n",
      "AGAVE_TENANTS_API_BASEURL=https://agave-auth.solveij.com/tenants\n",
      "AGAVE_USERNAME=dooley\n",
      "APP_NAME=funwave-tvd-nectar-dooley\n",
      "DEPLOYMENT_PATH=agave-deployment\n",
      "DOCKERHUB_NAME=dooley\n",
      "DOMAIN=nectar.org\n",
      "EMAIL=deardooley@gmail.com\n",
      "EXEC_MACHINE=nectar-exec-dooley\n",
      "HOME_DIR=/home/jovyan\n",
      "MACHINE_IP=204.90.47.30\n",
      "MACHINE_NAME=nectar\n",
      "MACHINE_USERNAME=jovyan\n",
      "PBTOK=**HIDDEN**\n",
      "PORT=10022\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/voup3yvo\n",
      "SCRATCH_DIR=/home/jovyan\n",
      "STORAGE_MACHINE=nectar-storage-dooley\n",
      "WORK_DIR=/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/agave\n",
    "\n",
    "%cd ~/agave\n",
    "\n",
    "!pip3 install --upgrade setvar\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from setvar import *\n",
    "from time import sleep\n",
    "\n",
    "# This cell enables inline plotting in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "loadvar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Storage Machine   \n",
    "\n",
    "Agave wants to know which place (or places) you want to store the data associated with your jobs. Here, we're going to set that up. Authentication to the storage machine will be through SSH keys. The key and public key files, however, contain newlines. To encode them in Json (the data format used by Agave), we will run the jsonpki command on each file. Next, we will store its contents in the environment for use by setvar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!jsonpki --public ~/.ssh/id_rsa.pub > ~/.ssh/id_rsa.pub.txt\n",
    "!jsonpki --private ~/.ssh/id_rsa > ~/.ssh/id_rsa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file `/home/jovyan/.ssh/id_rsa.pub.txt'\n",
      "Reading file `/home/jovyan/.ssh/id_rsa.txt'\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PUB_KEY\"]=readfile(\"${HOME}/.ssh/id_rsa.pub.txt\").strip()\n",
    "os.environ[\"PRIV_KEY\"]=readfile(\"${HOME}/.ssh/id_rsa.txt\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we create the json file used to describe the storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `nectar-storage-dooley.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"${STORAGE_MACHINE}.txt\",\"\"\"{\n",
    "    \"id\": \"${STORAGE_MACHINE}\",\n",
    "    \"name\": \"${MACHINE_NAME} storage (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${DOMAIN}\",\n",
    "    \"type\": \"STORAGE\",\n",
    "    \"storage\": {\n",
    "        \"host\": \"${MACHINE_IP}\",\n",
    "        \"port\": ${PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tell Agave about the machine. You can re-run the previous cell and the next one if you want to change the definition of your storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added system nectar-storage-dooley\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!systems-addupdate -F ${STORAGE_MACHINE}.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the Agave command `files-list`. This provides a check that we've set up the storage machine correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      ".bash_logout\r\n",
      ".bashrc\r\n",
      ".cache\r\n",
      ".docker\r\n"
     ]
    }
   ],
   "source": [
    "!files-list -S ${STORAGE_MACHINE} ./ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting up the Execution Machine</h2>\n",
    "\n",
    "You may not always wish to store your data on the same machine you run your jobs on. However, in this tutorial, we will assume that you do. The description for the execution machine is much like the storage machine. However, there are a few more pieces of information you'll need to provide. In this example, we are going to call commands directly on the host as opposed to using a batch queue scheduler. It is slightly simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `nectar-exec-dooley.txt'\n"
     ]
    }
   ],
   "source": [
    "# Edit any parts of this file that you know need to be changed for your machine.\n",
    "writefile(\"${EXEC_MACHINE}.txt\",\"\"\"\n",
    "{\n",
    "    \"id\": \"${EXEC_MACHINE}\",\n",
    "    \"name\": \"${MACHINE_NAME} (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${DOMAIN}\",\n",
    "    \"public\": false,\n",
    "    \"status\": \"UP\",\n",
    "    \"type\": \"EXECUTION\",\n",
    "    \"executionType\": \"CLI\",\n",
    "    \"scheduler\" : \"FORK\",\n",
    "    \"environment\": null,\n",
    "    \"scratchDir\" : \"${SCRATCH_DIR}\",\n",
    "    \"queues\": [\n",
    "        {\n",
    "            \"name\": \"none\",\n",
    "            \"default\": true,\n",
    "            \"maxJobs\": 10,\n",
    "            \"maxUserJobs\": 10,\n",
    "            \"maxNodes\": 6,\n",
    "            \"maxProcessorsPerNode\": 6,\n",
    "            \"minProcessorsPerNode\": 1,\n",
    "            \"maxRequestedTime\": \"00:30:00\"\n",
    "        }\n",
    "    ],\n",
    "    \"login\": {\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        },\n",
    "        \"host\": \"${MACHINE_IP}\",\n",
    "        \"port\": ${PORT},\n",
    "        \"protocol\": \"SSH\"\n",
    "    },\n",
    "    \"maxSystemJobs\": 50,\n",
    "    \"maxSystemJobsPerUser\": 50,\n",
    "    \"storage\": {\n",
    "        \"host\": \"${MACHINE_IP}\",\n",
    "        \"port\": ${PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    },\n",
    "    \"workDir\": \"${WORK_DIR}\"\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added system nectar-exec-dooley\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!systems-addupdate -F ${EXEC_MACHINE}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      ".bash_logout\r\n",
      ".bashrc\r\n",
      ".cache\r\n",
      ".docker\r\n"
     ]
    }
   ],
   "source": [
    "# Test to see if this worked...\n",
    "!files-list -S ${EXEC_MACHINE} ./ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the Application</h3>\n",
    "Agave allows us to describe custom allocations, limiting users to run a specific job. In this case, we're going to create a simple \"fork\" scheduler that just takes the command we want to run as a job parameter. The wrapper file is a shell script we will run on the execution machine. If we were using a scheduler, this would be our batch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-wrapper.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-wrapper.txt\",\"\"\"\n",
    "#!/bin/bash\n",
    "\\${command}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Agave commands, we make a directory on the storage server an deploy our wrapper file there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully created folder agave-deployment\u001b[0m\n",
      "Uploading fork-wrapper.txt...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "!files-mkdir -S ${STORAGE_MACHINE} -N ${DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-wrapper.txt -S ${STORAGE_MACHINE} ${DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All agave applications require a test file. The test file is a free form text file which allows you to specify what resources you might need to test your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-test.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-test.txt\",\"\"\"\n",
    "command=date\n",
    "fork-wrapper.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully created folder agave-deployment\u001b[0m\n",
      "Uploading fork-test.txt...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "!files-mkdir -S ${STORAGE_MACHINE} -N ${DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-test.txt -S ${STORAGE_MACHINE} ${DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like everything else in Agave, we describe our application with Json. We specifiy which machines the application will use, what method it will use for submitting jobs, job parameters and files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-app.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-app.txt\",\"\"\"\n",
    "{  \n",
    "   \"name\":\"${AGAVE_USERNAME}-${MACHINE_NAME}-fork\",\n",
    "   \"version\":\"1.0\",\n",
    "   \"label\":\"Runs a command\",\n",
    "   \"shortDescription\":\"Runs a command\",\n",
    "   \"longDescription\":\"\",\n",
    "   \"deploymentSystem\":\"${STORAGE_MACHINE}\",\n",
    "   \"deploymentPath\":\"${DEPLOYMENT_PATH}\",\n",
    "   \"templatePath\":\"fork-wrapper.txt\",\n",
    "   \"testPath\":\"fork-test.txt\",\n",
    "   \"executionSystem\":\"${EXEC_MACHINE}\",\n",
    "   \"executionType\":\"CLI\",\n",
    "   \"parallelism\":\"SERIAL\",\n",
    "   \"modules\":[],\n",
    "   \"inputs\":[\n",
    "         {   \n",
    "         \"id\":\"datafile\",\n",
    "         \"details\":{  \n",
    "            \"label\":\"Data file\",\n",
    "            \"description\":\"\",\n",
    "            \"argument\":null,\n",
    "            \"showArgument\":false\n",
    "         },\n",
    "         \"value\":{  \n",
    "            \"default\":\"/dev/null\",\n",
    "            \"order\":0,\n",
    "            \"required\":false,\n",
    "            \"validator\":\"\",\n",
    "            \"visible\":true\n",
    "         }\n",
    "      }   \n",
    "   ],\n",
    "   \"parameters\":[{\n",
    "     \"id\" : \"command\",\n",
    "     \"value\" : {\n",
    "       \"visible\":true,\n",
    "       \"required\":true,\n",
    "       \"type\":\"string\",\n",
    "       \"order\":0,\n",
    "       \"enquote\":false,\n",
    "       \"default\":\"/bin/date\",\n",
    "       \"validator\":null\n",
    "     },\n",
    "     \"details\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     },\n",
    "     \"semantics\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     }\n",
    "   }],\n",
    "   \"outputs\":[]\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added app dooley-nectar-fork-1.0\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!apps-addupdate -F fork-app.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running Jobs</h2>\n",
    "Now that we have specified our application using Agave, it is time to try running jobs. To start a job we, once again, create a Json file. The Json file describes the app, what resource to run on, as well as how and when to send notifications. Notifications are delivered by callback url. EMAIL is the easiest type to configure, but we show here how to send webhook notifications to the popular [RequestBin](https://requestb.in/). \n",
    "\n",
    "The way this job is configured, it will only send email notifications for FINISHED or FAILURE. The requestbin will receive notifications of every job event until it reaches a terminal state. Other statuses exist, however. You can find them at http://docs.agaveplatform.org/#job-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `job.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"job.txt\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${EXEC_MACHINE}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${EMAIL}\",\n",
    "      \"event\":\"FINISHED\",\n",
    "      \"persistent\":false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"${EMAIL}\",\n",
    "      \"event\":\"FAILED\",\n",
    "      \"persistent\":false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"echo hello\"\n",
    "   }\n",
    " }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the setvar() command can evalute `$()` style bash shell substitutions, we will use it to submit our job. This will capture the output of the submit command, and allow us to parse it for the JOB_ID. We'll use the JOB_ID in several subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT=Successfully submitted job 8508968551844286951-242ac114-0001-007\n",
      "JOB_ID=8508968551844286951-242ac114-0001-007\n"
     ]
    }
   ],
   "source": [
    "setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F job.txt)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Job Monitoring and Output</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, the requestbin you registered will receive webhooks from Agave every time a job event occurs. To monitor this in real time, evaluate the next cell an visit the printed url in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://requestbin.agaveapi.co/voup3yvo?inspect\r\n"
     ]
    }
   ],
   "source": [
    "!echo ${REQUESTBIN_URL}?inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also monitor the job status by polling. Note that the notifications you receive via email and webhook are less wasteful of resources. However, we show you this for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=FINISHED\n"
     ]
    }
   ],
   "source": [
    "for iter in range(20):\n",
    "    setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "    stat = os.environ[\"STAT\"]\n",
    "    sleep(5.0)\n",
    "    if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs-history command provides you a record of the steps of what your job did. If your job fails for some reason, this is your best diagnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs-history 2784026591666368025-242ac11b-0001-007\n",
      "\u001b[1;0mJob accepted and queued for submission.\n",
      "Skipping staging. No input data associated with this job.\n",
      "Preparing job for submission.\n",
      "Attempt 1 to submit job\n",
      "Fetching app assets from agave://jetstream-storage-stevenrbrandt/agave-deployment\n",
      "Staging runtime assets to agave://jetstream-exec-stevenrbrandt//home/jovyan/stevenrbrandt/job-2784026591666368025-242ac11b-0001-007-fork-command-1\n",
      "CLI job successfully forked as process id 15413\n",
      "CLI job successfully forked as process id 15413\n",
      "Job receieved duplicate RUNNING notification\n",
      "Job completed execution\n",
      "Job completed. Skipping archiving at user request.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!echo jobs-history ${JOB_ID}\n",
    "!jobs-history ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command shows you the job id's and status of the last 5 jobs you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m2784026591666368025-242ac11b-0001-007 FINISHED\r\n",
      "7195273770654297625-242ac11b-0001-007 FINISHED\r\n",
      "2035779517029608985-242ac11b-0001-007 FINISHED\r\n",
      "7419306274200808985-242ac11b-0001-007 FINISHED\r\n",
      "1021257183143390745-242ac11b-0001-007 FINISHED\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-list -l 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next command provides you with a list of all the files generated by your job. You can use it to figure out which files you want to retrieve with jobs-output-get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m.agave.archive\r\n",
      ".agave.log\r\n",
      "fork-command-1.err\r\n",
      "fork-command-1.ipcexe\r\n",
      "fork-command-1.out\r\n",
      "fork-command-1.pid\r\n",
      "fork-test.txt\r\n",
      "fork-wrapper.txt\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-list --rich --filter=type,length,name ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.out\n",
    "!cat fork-command-1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard error output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.err\n",
    "!cat fork-command-1.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Automating</h3>\n",
    "Because we're working in Python, we can simply glue the above steps together and create a script to run jobs for us and fetch the standard output. Let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing runagavecmd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile runagavecmd.py\n",
    "from setvar import *\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def runagavecmd(cmd,infile=None):\n",
    "    setvar(\"REMOTE_COMMAND=\"+cmd)\n",
    "    # The input file is an optional parameter, both\n",
    "    # to our function and to the Agave application.\n",
    "    if infile == None:\n",
    "        setvar(\"INPUTS={}\")\n",
    "    else:\n",
    "        setvar('INPUTS={\"datafile\":\"'+infile+'\"}')\n",
    "    setvar(\"JOB_FILE=job-remote-$PID.txt\")\n",
    "    # Create the Json for the job file.\n",
    "    writefile(\"$JOB_FILE\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${EXEC_MACHINE}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"${REMOTE_COMMAND}\"\n",
    "   },\n",
    "   \"inputs\":${INPUTS}\n",
    " }\"\"\")\n",
    "    # Run the job and capture the output.\n",
    "    setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F $JOB_FILE)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")\n",
    "    # Poll and wait for the job to finish.\n",
    "    for iter in range(80): # Excessively generous\n",
    "        setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "        stat = os.environ[\"STAT\"]\n",
    "        sleep(5.0)\n",
    "        if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "            break\n",
    "    # Fetch the job output from the remote machine\n",
    "    setvar(\"CMD=jobs-output-get ${JOB_ID} fork-command-1.out\")\n",
    "    os.system(os.environ[\"CMD\"])\n",
    "    print(\"All done! Output follows.\")\n",
    "    # Load the output into memory\n",
    "    output=readfile(\"fork-command-1.out\")\n",
    "    print(\"=\" * 70)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'runagavecmd' from '/home/jovyan/agave/runagavecmd.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import runagavecmd as r\n",
    "import imp\n",
    "imp.reload(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=lscpu\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-11198.txt\n",
      "Writing file `job-remote-11198.txt'\n",
      "OUTPUT=Successfully submitted job 7682515682713136665-242ac11b-0001-007\n",
      "JOB_ID=7682515682713136665-242ac11b-0001-007\n",
      "STAT=PENDING\n",
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=STAGED\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=RUNNING\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 7682515682713136665-242ac11b-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                6\n",
      "On-line CPU(s) list:   0-5\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    1\n",
      "Socket(s):             6\n",
      "NUMA node(s):          1\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 63\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz\n",
      "Stepping:              2\n",
      "CPU MHz:               2494.224\n",
      "BogoMIPS:              4988.44\n",
      "Virtualization:        VT-x\n",
      "Hypervisor vendor:     KVM\n",
      "Virtualization type:   full\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              4096K\n",
      "NUMA node0 CPU(s):     0-5\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl eagerfpu pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r.runagavecmd(\"lscpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Permissions and Sharing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the users and the permssions they have to look at the given job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mdooley READ WRITE \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-pems-list ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grant read permission to the user, ktraxler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully updated permission for ktraxler\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# permissions: READ, WRITE, READ_WRITE, ALL, NONE\n",
    "!jobs-pems-update -u ktraxler -p READ ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the list again and see the modified result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mdooley READ WRITE \r\n",
      "ktraxler READ \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-pems-list ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mdooley READ WRITE EXECUTE \r\n",
      "dooley READ WRITE EXECUTE \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!apps-pems-list ${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing for the application itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully updated permission for ktraxler\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# permissions: READ, WRITE, EXECUTE, READ_WRITE, READ_EXECUTE, WRITE_EXECUTE, ALL, and NONE\n",
    "!apps-pems-update -u ktraxler -p READ_EXECUTE ${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mdooley READ WRITE EXECUTE \r\n",
      "ktraxler READ EXECUTE \r\n",
      "dooley READ WRITE EXECUTE \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!apps-pems-list ${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the TOGO web portal  \n",
    "\n",
    "Follow the link below to run your job from a web portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://togo.solveij.com/app/#/apps/dooley-nectar-fork-1.0/run\r\n"
     ]
    }
   ],
   "source": [
    "!echo http://togo.solveij.com/app/#/apps/${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
